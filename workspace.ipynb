{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04bc4815",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb17c02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Benja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from torch import nn\n",
    "import neural_network\n",
    "import losses\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1893665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/clean2_data_normalized.csv\", index_col=0)\n",
    "df = pd.read_csv(\"cleaned_data_ext_norm.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebf90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "test_size = 0.15\n",
    "X = df.drop(columns=[\"TARGET\", \"SK_ID_CURR\"], axis=1)\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "# note: stratify=df.buy generates\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=test_size, random_state=seed, stratify=y)\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d5c0bbf",
   "metadata": {},
   "source": [
    "### Linear Regression --> Might want to switch this to soft SVM classifier bec this is not a regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d81f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # linear model \n",
    "# x = sm.add_constant(X_train, prepend=False)\n",
    "# lin_mod = sm.OLS(y_train, x.astype(float))\n",
    "# lin_mod = lin_mod.fit()\n",
    "# # print(lin_mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f1f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_tr = lin_mod.predict(x.astype(float))\n",
    "# y_pred_te = lin_mod.predict(sm.add_constant(X_test, prepend=False).astype(float))\n",
    "\n",
    "# accuracy_tr = accuracy_score(y_train, y_pred_tr)\n",
    "# print(\"Train Accuracy: %.2f%%\" % (accuracy_tr * 100.0))\n",
    "\n",
    "# accuracy_te = accuracy_score(y_test, y_pred_te)\n",
    "# print(\"Test Accuracy: %.2f%%\" % (accuracy_te * 100.0))\n",
    "\n",
    "# print('f1 score on train set', f1_score(y_train, y_pred_tr))\n",
    "# print('f1 score on test set', f1_score(y_test, y_pred_te))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10fd7ee2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d27904b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=100000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=100000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=100000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced', max_iter=100000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ea4ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score on train set 0.25595109517432063\n",
      "f1 score on test set 0.25490674143606\n"
     ]
    }
   ],
   "source": [
    "f1_tr = f1_score(y_train, logreg.predict(X_train))\n",
    "print('f1 score on train set', f1_tr)\n",
    "\n",
    "f1_te = f1_score(y_test, logreg.predict(X_test))\n",
    "print('f1 score on test set', f1_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab724c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Train Set: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81    207743\n",
      "           1       0.16      0.68      0.26     17416\n",
      "\n",
      "    accuracy                           0.69    225159\n",
      "   macro avg       0.56      0.69      0.53    225159\n",
      "weighted avg       0.90      0.69      0.76    225159\n",
      "\n",
      "Classification Report for Test Set: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.81     36661\n",
      "           1       0.16      0.68      0.25      3074\n",
      "\n",
      "    accuracy                           0.69     39735\n",
      "   macro avg       0.56      0.69      0.53     39735\n",
      "weighted avg       0.90      0.69      0.76     39735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report for Train Set: \\n', classification_report(y_train, logreg.predict(X_train)))\n",
    "print('Classification Report for Test Set: \\n', classification_report(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a34b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144420, 63323, 5567, 11849)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, logreg.predict(X_train)).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0b0416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6877686398582332\n",
      "0.6868005480660107\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, logreg.predict(X_train)))\n",
    "print(roc_auc_score(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb415125",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosted Trees\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5176e9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.9226502160695331, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.9226502160695331, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.9226502160695331, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(base_score=np.sum(y_train == 0)/len(y_train), max_depth=5, n_estimators = 1000, subsample=0.8, reg_lambda = 1)\n",
    "xgb_model.fit(X_train, y_train, sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87ab5ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 89.97%\n",
      "Test Accuracy: 81.91%\n",
      "f1 score on train set 0.6013870017116942\n",
      "f1 score on test set 0.2595797280593325\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = xgb_model.predict(X_train)\n",
    "y_pred_te = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_tr = accuracy_score(y_train, y_pred_tr)\n",
    "print(\"Train Accuracy: %.2f%%\" % (accuracy_tr * 100.0))\n",
    "\n",
    "accuracy_te = accuracy_score(y_test, y_pred_te)\n",
    "print(\"Test Accuracy: %.2f%%\" % (accuracy_te * 100.0))\n",
    "\n",
    "print('f1 score on train set', f1_score(y_train, y_pred_tr))\n",
    "print('f1 score on test set', f1_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1a7f3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185530, 22213, 376, 17040)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_tr).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec29a7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9357426365499024\n",
      "0.6316515521583153\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, y_pred_tr))\n",
    "print(roc_auc_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80fff751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>0.022298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>0.016468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>0.014159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car_owned_less_10</td>\n",
       "      <td>0.014138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Higher education</td>\n",
       "      <td>0.013631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>FLAG_EMP_PHONE</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Businessman</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Student</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Unemployed</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>XNA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Importance\n",
       "0         EXT_SOURCE_3    0.022298\n",
       "1          CODE_GENDER    0.016468\n",
       "2         EXT_SOURCE_2    0.014159\n",
       "3    car_owned_less_10    0.014138\n",
       "4     Higher education    0.013631\n",
       "..                 ...         ...\n",
       "147     FLAG_EMP_PHONE    0.000000\n",
       "148        Businessman    0.000000\n",
       "149            Student    0.000000\n",
       "150         Unemployed    0.000000\n",
       "151                XNA    0.000000\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dict= {}\n",
    "for col, val in sorted(zip(X_train.columns, xgb_model.feature_importances_),key=lambda x:x[1],reverse=True):\n",
    "  feat_dict[col]=val\n",
    "feat_df = pd.DataFrame({'Feature':feat_dict.keys(),'Importance':feat_dict.values()})\n",
    "feat_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f56127f5",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71758d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 loss 1.5085399150848389\n",
      "epoch 50 loss 1.474826455116272\n",
      "epoch 75 loss 1.450129508972168\n",
      "epoch 100 loss 1.4304406642913818\n",
      "epoch 125 loss 1.4173903465270996\n",
      "epoch 150 loss 1.4090189933776855\n",
      "epoch 175 loss 1.404041051864624\n",
      "epoch 200 loss 1.4012277126312256\n",
      "epoch 225 loss 1.399289608001709\n",
      "epoch 250 loss 1.3975447416305542\n",
      "epoch 275 loss 1.395843744277954\n",
      "epoch 300 loss 1.3940802812576294\n",
      "epoch 325 loss 1.3922231197357178\n",
      "epoch 350 loss 1.390364646911621\n",
      "epoch 375 loss 1.3883862495422363\n",
      "epoch 400 loss 1.386263132095337\n",
      "epoch 425 loss 1.384049892425537\n",
      "epoch 450 loss 1.38181734085083\n",
      "epoch 475 loss 1.3796660900115967\n",
      "epoch 500 loss 1.3776581287384033\n",
      "epoch 525 loss 1.3756279945373535\n",
      "epoch 550 loss 1.3737499713897705\n",
      "epoch 575 loss 1.3718314170837402\n",
      "epoch 600 loss 1.3700330257415771\n",
      "epoch 625 loss 1.3682763576507568\n",
      "epoch 650 loss 1.3666285276412964\n",
      "epoch 675 loss 1.36503267288208\n",
      "epoch 700 loss 1.3635023832321167\n",
      "epoch 725 loss 1.362007737159729\n",
      "epoch 750 loss 1.360614538192749\n",
      "epoch 775 loss 1.3592066764831543\n",
      "epoch 800 loss 1.3578987121582031\n",
      "epoch 825 loss 1.3565738201141357\n",
      "epoch 850 loss 1.3552629947662354\n",
      "epoch 875 loss 1.3539297580718994\n",
      "epoch 900 loss 1.3526325225830078\n",
      "epoch 925 loss 1.3513994216918945\n",
      "epoch 950 loss 1.3501923084259033\n",
      "epoch 975 loss 1.3490263223648071\n",
      "epoch 1000 loss 1.3478975296020508\n"
     ]
    }
   ],
   "source": [
    "n, d = X_train.shape\n",
    "input_dim = d\n",
    "hidden_dim = d//2\n",
    "output_dim = 1\n",
    "num_epochs = 1000\n",
    "model_nn = neural_network.Model(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',# {0: len(y_train)/np.sum(y_train == 0), 1: 1.5 * len(y_train)/np.sum(y_train == 1)},\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "model_nn = neural_network.train_regression_model(torch.tensor(X_train.values, dtype=torch.float32), \n",
    "                                      torch.tensor(y_train.values, dtype=torch.float32), \n",
    "                                      model_nn, \n",
    "                                      num_epochs, \n",
    "                                      loss_fn = losses.DiceBCELoss(weight=torch.tensor(classes_weights)),\n",
    "                                      # loss_fn = losses.DiceLoss(),\n",
    "                                      # loss_fn = nn.BCELoss(weight=torch.tensor(classes_weights)), \n",
    "                                      lr=1e-3, print_freq=25, display_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fa83c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 73.53%\n",
      "Test Accuracy: 72.43%\n",
      "f1 score on train set 0.28619685916555865\n",
      "f1 score on test set 0.2559608722233544\n"
     ]
    }
   ],
   "source": [
    "model_nn.eval()\n",
    "\n",
    "y_pred_tr = model_nn(torch.tensor(X_train.values, dtype=torch.float32)).detach().numpy().flatten()\n",
    "y_pred_tr = np.round(y_pred_tr)\n",
    "y_pred_te = model_nn(torch.tensor(X_test.values, dtype=torch.float32)).detach().numpy().flatten()\n",
    "y_pred_te = np.round(y_pred_te)\n",
    "\n",
    "accuracy_tr = accuracy_score(y_train, y_pred_tr)\n",
    "print(\"Train Accuracy: %.2f%%\" % (accuracy_tr * 100.0))\n",
    "\n",
    "accuracy_te = accuracy_score(y_test, y_pred_te)\n",
    "print(\"Test Accuracy: %.2f%%\" % (accuracy_te * 100.0))\n",
    "\n",
    "print('f1 score on train set', f1_score(y_train, y_pred_tr))\n",
    "print('f1 score on test set', f1_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54d600a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153624, 54119, 5470, 11946)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_tr).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a18b934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7127058064068424\n",
      "0.673288722783685\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, y_pred_tr))\n",
    "print(roc_auc_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485df4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
