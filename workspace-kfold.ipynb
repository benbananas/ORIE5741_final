{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04bc4815",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb17c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from torch import nn\n",
    "import neural_network\n",
    "import losses\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1893665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/clean2_data_normalized.csv\", index_col=0)\n",
    "df = pd.read_csv(\"cleaned_data_ext_norm.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebf90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "test_size = 0.15\n",
    "X = df.drop(columns=[\"TARGET\", \"SK_ID_CURR\"], axis=1)\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "\n",
    "\n",
    "# note: stratify=df.buy generates\n",
    "# X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=test_size, random_state=seed, stratify=y)\n",
    "# classes_weights = class_weight.compute_sample_weight(\n",
    "#     class_weight='balanced',\n",
    "#     y=y_train\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6da9d77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1:  0.2574704342330956\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
    "\n",
    "best_log_model = None\n",
    "max_log_f1 = 0\n",
    "\n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y.iloc[train_index] , y.iloc[test_index]\n",
    "     \n",
    "    logreg.fit(X_train,y_train)\n",
    "    pred_values = logreg.predict(X_test)\n",
    "     \n",
    "    f1_te = f1_score(y_test, pred_values)\n",
    "    if f1_te > max_log_f1:\n",
    "        max_log_f1 = f1_te\n",
    "        best_log_model = logreg\n",
    "\n",
    "print(\"Best F1: \", max_log_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1737dcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1:  0.2655255983035444\n"
     ]
    }
   ],
   "source": [
    "best_tree_model = None\n",
    "max_tree_f1 = 0\n",
    "\n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y.iloc[train_index] , y.iloc[test_index]\n",
    "\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_train\n",
    "    )\n",
    "\n",
    "    xgb_model = XGBClassifier(base_score=np.sum(y_train == 0)/len(y_train), max_depth=10)\n",
    "    xgb_model.fit(X_train, y_train, sample_weight=classes_weights)\n",
    "     \n",
    "    pred_values = xgb_model.predict(X_test)\n",
    "     \n",
    "    f1_te = f1_score(y_test, pred_values)\n",
    "    if f1_te > max_tree_f1:\n",
    "        max_tree_f1 = f1_te\n",
    "        best_tree_model = xgb_model\n",
    "\n",
    "print(\"Best F1: \", max_tree_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c0b2dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>0.024208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Higher education</td>\n",
       "      <td>0.022153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>0.017239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car_owned_less_10</td>\n",
       "      <td>0.013945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>0.013902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Pensioner</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Student</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Unemployed</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Industry: type 6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>XNA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Importance\n",
       "0         EXT_SOURCE_3    0.024208\n",
       "1     Higher education    0.022153\n",
       "2         EXT_SOURCE_2    0.017239\n",
       "3    car_owned_less_10    0.013945\n",
       "4          CODE_GENDER    0.013902\n",
       "..                 ...         ...\n",
       "147          Pensioner    0.000000\n",
       "148            Student    0.000000\n",
       "149         Unemployed    0.000000\n",
       "150   Industry: type 6    0.000000\n",
       "151                XNA    0.000000\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dict= {}\n",
    "for col, val in sorted(zip(X_train.columns, best_tree_model.feature_importances_),key=lambda x:x[1],reverse=True):\n",
    "  feat_dict[col]=val\n",
    "feat_df = pd.DataFrame({'Feature':feat_dict.keys(),'Importance':feat_dict.values()})\n",
    "feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "811bb32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 152 artists>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(feat_df['Feature'][:], feat_df['Importance'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "934563bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1:  0.2632340179346254\n"
     ]
    }
   ],
   "source": [
    "best_nn_model = None\n",
    "max_nn_f1 = 0\n",
    "\n",
    "output_dim = 1\n",
    "num_epochs = 1000\n",
    "\n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y.iloc[train_index] , y.iloc[test_index]\n",
    "\n",
    "\n",
    "    n, d = X_train.shape\n",
    "    input_dim = d\n",
    "    hidden_dim = d//2\n",
    "    model_nn = neural_network.Model(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "    classes_weights = class_weight.compute_sample_weight(\n",
    "        class_weight='balanced',\n",
    "        y=y_train\n",
    "    )\n",
    "\n",
    "    \n",
    "    model_nn = neural_network.train_regression_model(torch.tensor(X_train.values, dtype=torch.float32), \n",
    "                                        torch.tensor(y_train.values, dtype=torch.float32), \n",
    "                                        model_nn, \n",
    "                                        num_epochs, \n",
    "                                        loss_fn = losses.DiceBCELoss(weight=torch.tensor(classes_weights)),\n",
    "                                        lr=1e-3, print_freq=25, display_loss=False)\n",
    "\n",
    "    model_nn.eval()\n",
    "\n",
    "    y_pred_te = model_nn(torch.tensor(X_test.values, dtype=torch.float32)).detach().numpy().flatten()\n",
    "    y_pred_te = np.round(y_pred_te)\n",
    "     \n",
    "    f1_te = f1_score(y_test, y_pred_te)\n",
    "    if f1_te > max_nn_f1:\n",
    "        max_nn_f1 = f1_te\n",
    "        best_nn_model = model_nn\n",
    "\n",
    "print(\"Best F1: \", max_nn_f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d5c0bbf",
   "metadata": {},
   "source": [
    "### Linear Regression --> Might want to switch this to soft SVM classifier bec this is not a regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d81f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # linear model \n",
    "# x = sm.add_constant(X_train, prepend=False)\n",
    "# lin_mod = sm.OLS(y_train, x.astype(float))\n",
    "# lin_mod = lin_mod.fit()\n",
    "# # print(lin_mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f1f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_tr = lin_mod.predict(x.astype(float))\n",
    "# y_pred_te = lin_mod.predict(sm.add_constant(X_test, prepend=False).astype(float))\n",
    "\n",
    "# accuracy_tr = accuracy_score(y_train, y_pred_tr)\n",
    "# print(\"Train Accuracy: %.2f%%\" % (accuracy_tr * 100.0))\n",
    "\n",
    "# accuracy_te = accuracy_score(y_test, y_pred_te)\n",
    "# print(\"Test Accuracy: %.2f%%\" % (accuracy_te * 100.0))\n",
    "\n",
    "# print('f1 score on train set', f1_score(y_train, y_pred_tr))\n",
    "# print('f1 score on test set', f1_score(y_test, y_pred_te))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10fd7ee2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d27904b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=100000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=100000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=100000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced', max_iter=100000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ea4ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score on train set 0.25595109517432063\n",
      "f1 score on test set 0.25490674143606\n"
     ]
    }
   ],
   "source": [
    "f1_tr = f1_score(y_train, logreg.predict(X_train))\n",
    "print('f1 score on train set', f1_tr)\n",
    "\n",
    "f1_te = f1_score(y_test, logreg.predict(X_test))\n",
    "print('f1 score on test set', f1_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab724c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Train Set: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81    207743\n",
      "           1       0.16      0.68      0.26     17416\n",
      "\n",
      "    accuracy                           0.69    225159\n",
      "   macro avg       0.56      0.69      0.53    225159\n",
      "weighted avg       0.90      0.69      0.76    225159\n",
      "\n",
      "Classification Report for Test Set: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.81     36661\n",
      "           1       0.16      0.68      0.25      3074\n",
      "\n",
      "    accuracy                           0.69     39735\n",
      "   macro avg       0.56      0.69      0.53     39735\n",
      "weighted avg       0.90      0.69      0.76     39735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report for Train Set: \\n', classification_report(y_train, logreg.predict(X_train)))\n",
    "print('Classification Report for Test Set: \\n', classification_report(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a34b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144420, 63323, 5567, 11849)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, logreg.predict(X_train)).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0b0416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6877686398582332\n",
      "0.6868005480660107\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, logreg.predict(X_train)))\n",
    "print(roc_auc_score(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb415125",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosted Trees\n",
    "\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5176e9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.9226502160695331, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.9226502160695331, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.9226502160695331, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(base_score=np.sum(y_train == 0)/len(y_train), max_depth=5, n_estimators = 1000, subsample=0.8, reg_lambda = 1)\n",
    "xgb_model.fit(X_train, y_train, sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87ab5ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 89.97%\n",
      "Test Accuracy: 81.91%\n",
      "f1 score on train set 0.6013870017116942\n",
      "f1 score on test set 0.2595797280593325\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = xgb_model.predict(X_train)\n",
    "y_pred_te = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_tr = accuracy_score(y_train, y_pred_tr)\n",
    "print(\"Train Accuracy: %.2f%%\" % (accuracy_tr * 100.0))\n",
    "\n",
    "accuracy_te = accuracy_score(y_test, y_pred_te)\n",
    "print(\"Test Accuracy: %.2f%%\" % (accuracy_te * 100.0))\n",
    "\n",
    "print('f1 score on train set', f1_score(y_train, y_pred_tr))\n",
    "print('f1 score on test set', f1_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1a7f3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185530, 22213, 376, 17040)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_tr).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec29a7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9357426365499024\n",
      "0.6316515521583153\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, y_pred_tr))\n",
    "print(roc_auc_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80fff751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>0.022298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>0.016468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>0.014159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car_owned_less_10</td>\n",
       "      <td>0.014138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Higher education</td>\n",
       "      <td>0.013631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>FLAG_EMP_PHONE</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Businessman</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Student</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Unemployed</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>XNA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Importance\n",
       "0         EXT_SOURCE_3    0.022298\n",
       "1          CODE_GENDER    0.016468\n",
       "2         EXT_SOURCE_2    0.014159\n",
       "3    car_owned_less_10    0.014138\n",
       "4     Higher education    0.013631\n",
       "..                 ...         ...\n",
       "147     FLAG_EMP_PHONE    0.000000\n",
       "148        Businessman    0.000000\n",
       "149            Student    0.000000\n",
       "150         Unemployed    0.000000\n",
       "151                XNA    0.000000\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dict= {}\n",
    "for col, val in sorted(zip(X_train.columns, xgb_model.feature_importances_),key=lambda x:x[1],reverse=True):\n",
    "  feat_dict[col]=val\n",
    "feat_df = pd.DataFrame({'Feature':feat_dict.keys(),'Importance':feat_dict.values()})\n",
    "feat_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f56127f5",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71758d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 loss 1.5085399150848389\n",
      "epoch 50 loss 1.474826455116272\n",
      "epoch 75 loss 1.450129508972168\n",
      "epoch 100 loss 1.4304406642913818\n",
      "epoch 125 loss 1.4173903465270996\n",
      "epoch 150 loss 1.4090189933776855\n",
      "epoch 175 loss 1.404041051864624\n",
      "epoch 200 loss 1.4012277126312256\n",
      "epoch 225 loss 1.399289608001709\n",
      "epoch 250 loss 1.3975447416305542\n",
      "epoch 275 loss 1.395843744277954\n",
      "epoch 300 loss 1.3940802812576294\n",
      "epoch 325 loss 1.3922231197357178\n",
      "epoch 350 loss 1.390364646911621\n",
      "epoch 375 loss 1.3883862495422363\n",
      "epoch 400 loss 1.386263132095337\n",
      "epoch 425 loss 1.384049892425537\n",
      "epoch 450 loss 1.38181734085083\n",
      "epoch 475 loss 1.3796660900115967\n",
      "epoch 500 loss 1.3776581287384033\n",
      "epoch 525 loss 1.3756279945373535\n",
      "epoch 550 loss 1.3737499713897705\n",
      "epoch 575 loss 1.3718314170837402\n",
      "epoch 600 loss 1.3700330257415771\n",
      "epoch 625 loss 1.3682763576507568\n",
      "epoch 650 loss 1.3666285276412964\n",
      "epoch 675 loss 1.36503267288208\n",
      "epoch 700 loss 1.3635023832321167\n",
      "epoch 725 loss 1.362007737159729\n",
      "epoch 750 loss 1.360614538192749\n",
      "epoch 775 loss 1.3592066764831543\n",
      "epoch 800 loss 1.3578987121582031\n",
      "epoch 825 loss 1.3565738201141357\n",
      "epoch 850 loss 1.3552629947662354\n",
      "epoch 875 loss 1.3539297580718994\n",
      "epoch 900 loss 1.3526325225830078\n",
      "epoch 925 loss 1.3513994216918945\n",
      "epoch 950 loss 1.3501923084259033\n",
      "epoch 975 loss 1.3490263223648071\n",
      "epoch 1000 loss 1.3478975296020508\n"
     ]
    }
   ],
   "source": [
    "n, d = X_train.shape\n",
    "input_dim = d\n",
    "hidden_dim = d//2\n",
    "output_dim = 1\n",
    "num_epochs = 1000\n",
    "model_nn = neural_network.Model(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',# {0: len(y_train)/np.sum(y_train == 0), 1: 1.5 * len(y_train)/np.sum(y_train == 1)},\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "model_nn = neural_network.train_regression_model(torch.tensor(X_train.values, dtype=torch.float32), \n",
    "                                      torch.tensor(y_train.values, dtype=torch.float32), \n",
    "                                      model_nn, \n",
    "                                      num_epochs, \n",
    "                                      loss_fn = losses.DiceBCELoss(weight=torch.tensor(classes_weights)),\n",
    "                                      # loss_fn = losses.DiceLoss(),\n",
    "                                      # loss_fn = nn.BCELoss(weight=torch.tensor(classes_weights)), \n",
    "                                      lr=1e-3, print_freq=25, display_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fa83c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 73.53%\n",
      "Test Accuracy: 72.43%\n",
      "f1 score on train set 0.28619685916555865\n",
      "f1 score on test set 0.2559608722233544\n"
     ]
    }
   ],
   "source": [
    "model_nn.eval()\n",
    "\n",
    "y_pred_tr = model_nn(torch.tensor(X_train.values, dtype=torch.float32)).detach().numpy().flatten()\n",
    "y_pred_tr = np.round(y_pred_tr)\n",
    "y_pred_te = model_nn(torch.tensor(X_test.values, dtype=torch.float32)).detach().numpy().flatten()\n",
    "y_pred_te = np.round(y_pred_te)\n",
    "\n",
    "accuracy_tr = accuracy_score(y_train, y_pred_tr)\n",
    "print(\"Train Accuracy: %.2f%%\" % (accuracy_tr * 100.0))\n",
    "\n",
    "accuracy_te = accuracy_score(y_test, y_pred_te)\n",
    "print(\"Test Accuracy: %.2f%%\" % (accuracy_te * 100.0))\n",
    "\n",
    "print('f1 score on train set', f1_score(y_train, y_pred_tr))\n",
    "print('f1 score on test set', f1_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54d600a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153624, 54119, 5470, 11946)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_tr).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a18b934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7127058064068424\n",
      "0.673288722783685\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train, y_pred_tr))\n",
    "print(roc_auc_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485df4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
