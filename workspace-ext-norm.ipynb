{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04bc4815",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb17c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from torch import nn\n",
    "import neural_network\n",
    "import losses\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a197f",
   "metadata": {},
   "source": [
    "### Read In loan application data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1893665",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean2_data-ext-norm.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebf90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "test_size = 0.15\n",
    "X = df.drop(columns=[\"TARGET\", \"SK_ID_CURR\"], axis=1)\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "# note: stratify=df.buy generates\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=test_size, random_state=seed, stratify=y)\n",
    "classes_weights = class_weight.compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5c0bbf",
   "metadata": {},
   "source": [
    "### Linear Regression --> Might want to switch this to soft SVM classifier bec this is not a regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d81f5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # linear model \n",
    "# x = sm.add_constant(X_train, prepend=False)\n",
    "# lin_mod = sm.OLS(y_train, x.astype(float))\n",
    "# lin_mod = lin_mod.fit()\n",
    "# print(lin_mod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f1f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_tr = lin_mod.predict(x.astype(float))\n",
    "# y_pred_te = lin_mod.predict(sm.add_constant(X_test, prepend=False).astype(float))\n",
    "\n",
    "# accuracy_tr = accuracy_score(y_train, y_pred_tr)\n",
    "# print(\"Train Accuracy: %.2f%%\" % (accuracy_tr * 100.0))\n",
    "\n",
    "# accuracy_te = accuracy_score(y_test, y_pred_te)\n",
    "# print(\"Test Accuracy: %.2f%%\" % (accuracy_te * 100.0))\n",
    "\n",
    "# print('f1 score on train set', f1_score(y_train, y_pred_tr))\n",
    "# print('f1 score on test set', f1_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd7ee2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d27904b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ea4ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score on train set 0.17542486583184255\n",
      "f1 score on test set 0.17456678219141564\n"
     ]
    }
   ],
   "source": [
    "f1_tr = f1_score(y_train, logreg.predict(X_train))\n",
    "print('f1 score on train set', f1_tr)\n",
    "\n",
    "f1_te = f1_score(y_test, logreg.predict(X_test))\n",
    "print('f1 score on test set', f1_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab724c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Train Set: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.61      0.74    207743\n",
      "           1       0.10      0.54      0.18     17416\n",
      "\n",
      "    accuracy                           0.61    225159\n",
      "   macro avg       0.52      0.58      0.46    225159\n",
      "weighted avg       0.88      0.61      0.70    225159\n",
      "\n",
      "Classification Report for Test Set: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.62      0.75     36661\n",
      "           1       0.10      0.53      0.17      3074\n",
      "\n",
      "    accuracy                           0.61     39735\n",
      "   macro avg       0.52      0.57      0.46     39735\n",
      "weighted avg       0.88      0.61      0.70     39735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report for Train Set: \\n', classification_report(y_train, logreg.predict(X_train)))\n",
    "print('Classification Report for Test Set: \\n', classification_report(y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8a34b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127245, 80498, 8002, 9414)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, logreg.predict(X_train)).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb415125",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5176e9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.9226502160695331, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(base_score=np.sum(y_train == 0)/len(y_train), max_depth=10)\n",
    "xgb_model.fit(X_train, y_train, sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87ab5ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 89.12%\n",
      "Test Accuracy: 81.48%\n",
      "f1 score on train set 0.5766784207978981\n",
      "f1 score on test set 0.2577912254160363\n"
     ]
    }
   ],
   "source": [
    "y_pred_tr = xgb_model.predict(X_train)\n",
    "y_pred_te = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_tr = accuracy_score(y_train, y_pred_tr)\n",
    "print(\"Train Accuracy: %.2f%%\" % (accuracy_tr * 100.0))\n",
    "\n",
    "accuracy_te = accuracy_score(y_test, y_pred_te)\n",
    "print(\"Test Accuracy: %.2f%%\" % (accuracy_te * 100.0))\n",
    "\n",
    "print('f1 score on train set', f1_score(y_train, y_pred_tr))\n",
    "print('f1 score on test set', f1_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1a7f3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183988, 23755, 735, 16681)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_tr).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80fff751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXT_SOURCE_3</td>\n",
       "      <td>0.025717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXT_SOURCE_2</td>\n",
       "      <td>0.017720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NAME_CONTRACT_TYPE</td>\n",
       "      <td>0.015495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Higher education</td>\n",
       "      <td>0.015250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CODE_GENDER</td>\n",
       "      <td>0.014997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Pensioner</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Student</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Unemployed</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Advertising</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>XNA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Feature  Importance\n",
       "0          EXT_SOURCE_3    0.025717\n",
       "1          EXT_SOURCE_2    0.017720\n",
       "2    NAME_CONTRACT_TYPE    0.015495\n",
       "3      Higher education    0.015250\n",
       "4           CODE_GENDER    0.014997\n",
       "..                  ...         ...\n",
       "147           Pensioner    0.000000\n",
       "148             Student    0.000000\n",
       "149          Unemployed    0.000000\n",
       "150         Advertising    0.000000\n",
       "151                 XNA    0.000000\n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dict= {}\n",
    "for col, val in sorted(zip(X_train.columns, xgb_model.feature_importances_),key=lambda x:x[1],reverse=True):\n",
    "  feat_dict[col]=val\n",
    "feat_df = pd.DataFrame({'Feature':feat_dict.keys(),'Importance':feat_dict.values()})\n",
    "feat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56127f5",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71758d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 loss 50.85640335083008\n",
      "epoch 50 loss 50.85640335083008\n",
      "epoch 75 loss 50.85640335083008\n",
      "epoch 100 loss 50.85640335083008\n",
      "epoch 125 loss 50.85640335083008\n",
      "epoch 150 loss 50.85640335083008\n",
      "epoch 175 loss 50.85640335083008\n",
      "epoch 200 loss 50.85640335083008\n",
      "epoch 225 loss 50.85640335083008\n",
      "epoch 250 loss 50.85640335083008\n",
      "epoch 275 loss 50.85640335083008\n",
      "epoch 300 loss 50.85640335083008\n",
      "epoch 325 loss 50.85640335083008\n",
      "epoch 350 loss 50.85640335083008\n",
      "epoch 375 loss 50.85640335083008\n",
      "epoch 400 loss 50.85640335083008\n",
      "epoch 425 loss 50.85640335083008\n",
      "epoch 450 loss 50.85640335083008\n",
      "epoch 475 loss 50.85640335083008\n",
      "epoch 500 loss 50.85640335083008\n"
     ]
    }
   ],
   "source": [
    "n, d = X_train.shape\n",
    "input_dim = d\n",
    "hidden_dim = d//2\n",
    "output_dim = 1\n",
    "num_epochs = 500\n",
    "model_nn = neural_network.Model(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "model_nn = neural_network.train_regression_model(torch.tensor(X_train.values, dtype=torch.float32), \n",
    "                                      torch.tensor(y_train.values, dtype=torch.float32), \n",
    "                                      model_nn, \n",
    "                                      num_epochs, \n",
    "                                      loss_fn = losses.DiceBCELoss(weight=torch.tensor(classes_weights)),\n",
    "                                      # loss_fn = losses.DiceLoss(),\n",
    "                                      # loss_fn = nn.BCELoss(weight=torch.tensor(classes_weights)), \n",
    "                                      lr=1e-3, print_freq=25, display_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fa83c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 7.73%\n",
      "Test Accuracy: 7.74%\n",
      "f1 score on train set 0.143592703287643\n",
      "f1 score on test set 0.14361466046859306\n"
     ]
    }
   ],
   "source": [
    "model_nn.eval()\n",
    "\n",
    "y_pred_tr = model_nn(torch.tensor(X_train.values, dtype=torch.float32)).detach().numpy().flatten()\n",
    "y_pred_tr = np.round(y_pred_tr)\n",
    "y_pred_te = model_nn(torch.tensor(X_test.values, dtype=torch.float32)).detach().numpy().flatten()\n",
    "y_pred_te = np.round(y_pred_te)\n",
    "\n",
    "accuracy_tr = accuracy_score(y_train, y_pred_tr)\n",
    "print(\"Train Accuracy: %.2f%%\" % (accuracy_tr * 100.0))\n",
    "\n",
    "accuracy_te = accuracy_score(y_test, y_pred_te)\n",
    "print(\"Test Accuracy: %.2f%%\" % (accuracy_te * 100.0))\n",
    "\n",
    "print('f1 score on train set', f1_score(y_train, y_pred_tr))\n",
    "print('f1 score on test set', f1_score(y_test, y_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d600a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 207743, 0, 17416)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_train, y_pred_tr).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b934b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
